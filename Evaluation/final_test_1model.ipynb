{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b445564f-ec2a-4f2e-8e0f-7c59afa7128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import psutil\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim, mean_squared_error as mse\n",
    "from model.networks import Generator\n",
    "import lpips\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import AlexNet_Weights\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345e8d7b-bd19-496a-b53d-912973228bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage(stage):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"CPU Memory usage at {stage}: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"GPU Memory reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "def load_model_state(checkpoint_path, device):\n",
    "    print(f\"Loading model from {checkpoint_path}\")\n",
    "    if 'states_pt_places2.pth' in checkpoint_path:\n",
    "        generator = Generator(checkpoint=checkpoint_path, return_flow=True).to(device)\n",
    "    else:\n",
    "        generator = Generator(return_flow=True).to(device)\n",
    "        state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "        generator.load_state_dict(state_dict, strict=True)\n",
    "    print(\"Model loaded successfully\")\n",
    "    return generator\n",
    "\n",
    "def resize_output(output, original_size):\n",
    "    output_image = output.astype(np.uint8)\n",
    "    output_resized = cv2.resize(output_image, original_size)\n",
    "    return output_resized\n",
    "\n",
    "def calculate_metrics(original, inpainted, mask, lpips_model):\n",
    "    mask_np = np.array(mask.convert('L')) / 255\n",
    "    roi_original = original[mask_np > 0]\n",
    "    roi_inpainted = inpainted[mask_np > 0]\n",
    "    \n",
    "    side = int(np.ceil(np.sqrt(roi_original.shape[0])))\n",
    "    pad_size = side * side - roi_original.shape[0]\n",
    "    roi_original = np.pad(roi_original, ((0, pad_size), (0, 0)), mode='constant')\n",
    "    roi_inpainted = np.pad(roi_inpainted, ((0, pad_size), (0, 0)), mode='constant')\n",
    "    \n",
    "    roi_original = roi_original.reshape(side, side, 3)\n",
    "    roi_inpainted = roi_inpainted.reshape(side, side, 3)\n",
    "    \n",
    "    metrics = {\n",
    "        'psnr': psnr(roi_original, roi_inpainted, data_range=255),\n",
    "        'mae': np.mean(np.abs(roi_original - roi_inpainted)),\n",
    "        'mse': mse(roi_original, roi_inpainted)\n",
    "    }\n",
    "    \n",
    "    if side >= 32:\n",
    "        roi_original_tensor = torch.from_numpy(roi_original).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        roi_inpainted_tensor = torch.from_numpy(roi_inpainted).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "        \n",
    "        metrics['lpips'] = lpips_model(roi_original_tensor, roi_inpainted_tensor).item()\n",
    "    else:\n",
    "        metrics['lpips'] = 'N/A'\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def process_image(generator, image_path, mask_path, device, lpips_model):\n",
    "    image_pil = Image.open(image_path)\n",
    "    mask_pil = Image.open(mask_path)\n",
    "    original_size = image_pil.size\n",
    "    \n",
    "    if original_size[0] > 1000 or original_size[1] > 750:\n",
    "        return create_na_results()\n",
    "    \n",
    "    image_tensor = T.ToTensor()(image_pil).to(device)\n",
    "    mask_tensor = T.ToTensor()(mask_pil).to(device)\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()  # Reset peak stats\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            output = generator.infer(image_tensor, mask_tensor, return_vals=['inpainted', 'stage1', 'stage2', 'flow'])\n",
    "        elapsed_time = time.time() - start_time\n",
    "        mem_used = torch.cuda.max_memory_allocated() / 1024**2  # Peak memory in MB\n",
    "\n",
    "        original_np = np.array(image_pil).astype(np.uint8)\n",
    "        inpainted_resized_np = resize_output(output[0], original_size).astype(np.uint8)\n",
    "        metrics = calculate_metrics(original_np, inpainted_resized_np, mask_pil, lpips_model)\n",
    "        \n",
    "        results = {\n",
    "            'time': elapsed_time,\n",
    "            'memory': mem_used,\n",
    "            **metrics\n",
    "        }\n",
    "        return results\n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(f\"CUDA OOM for {image_path}. Skipping.\")\n",
    "            return create_na_results()\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def create_na_results():\n",
    "    return {\n",
    "        'time': 'N/A',\n",
    "        'memory': 'N/A',\n",
    "        'psnr': 'N/A',\n",
    "        'mae': 'N/A',\n",
    "        'mse': 'N/A',\n",
    "        'lpips': 'N/A'\n",
    "    }\n",
    "\n",
    "def init_lpips():\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        return lpips.LPIPS(net='alex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7475852f-9621-4870-98b4-66054bd1f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\tuant\\anaconda3\\envs\\torchgpu\\Lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "Loading model from C:/Users/tuant/Downloads/AI Thesis/FINAL_APP_AND_ANALYSIS/optimized_models\\pruned_model_6.pth\n",
      "Model loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|█████████████████████████████████████████████████████████████| 125/125 [02:16<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script completed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    models_dir = \"C:/Users/tuant/Downloads/AI Thesis/FINAL_APP_AND_ANALYSIS/optimized_models\"\n",
    "    images_dir = \"C:/Users/tuant/Downloads/AI Thesis/FINAL_APP_AND_ANALYSIS/examples/final_image\"\n",
    "    masks_dir = \"C:/Users/tuant/Downloads/AI Thesis/FINAL_APP_AND_ANALYSIS/examples/final_masks\"\n",
    "    results_csv_path = \"C:/Users/tuant/Downloads/AI Thesis/FINAL_APP_AND_ANALYSIS/results/results_single_model_6.csv\"\n",
    "\n",
    "    use_cuda_if_available = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() and use_cuda_if_available else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Select a single model (you can change this to test different models)\n",
    "    model_path = os.path.join(models_dir, \"pruned_model_6.pth\")\n",
    "    \n",
    "    images = glob.glob(os.path.join(images_dir, \"*.jpg\"))\n",
    "    masks = glob.glob(os.path.join(masks_dir, \"*.jpg\"))\n",
    "\n",
    "    lpips_model = init_lpips()\n",
    "\n",
    "    with open(results_csv_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Model', 'Image', 'Mask', 'Time (s)', 'Memory (MB)', 'PSNR', 'MAE', 'MSE', 'LPIPS']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        generator = load_model_state(model_path, device)\n",
    "        \n",
    "        for image_path in tqdm(images, desc=\"Processing images\"):\n",
    "            image_name = os.path.basename(image_path)\n",
    "            image_size = image_name.split('_')[1].split('.')[0]\n",
    "            \n",
    "            if image_size in ['4000x3000', '2000x1500']:\n",
    "                continue  # Skip these large images\n",
    "            \n",
    "            for mask_path in masks:\n",
    "                mask_name = os.path.basename(mask_path)\n",
    "                if image_size in mask_name:\n",
    "                    results = process_image(generator, image_path, mask_path, device, lpips_model)\n",
    "                    \n",
    "                    writer.writerow({\n",
    "                        'Model': os.path.basename(model_path),\n",
    "                        'Image': image_name,\n",
    "                        'Mask': mask_name,\n",
    "                        'Time (s)': f\"{results['time']:.4f}\" if results['time'] != 'N/A' else 'N/A',\n",
    "                        'Memory (MB)': f\"{results['memory']:.2f}\" if results['memory'] != 'N/A' else 'N/A',\n",
    "                        'PSNR': f\"{results['psnr']:.4f}\" if results['psnr'] != 'N/A' else 'N/A',\n",
    "                        'MAE': f\"{results['mae']:.4f}\" if results['mae'] != 'N/A' else 'N/A',\n",
    "                        'MSE': f\"{results['mse']:.4f}\" if results['mse'] != 'N/A' else 'N/A',\n",
    "                        'LPIPS': f\"{results['lpips']:.4f}\" if results['lpips'] != 'N/A' else 'N/A'\n",
    "                    })\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"Script completed successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ba6fd-7f63-41ef-aa00-31e5c5d6a373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
